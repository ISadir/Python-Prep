{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Ines Sadir\\Desktop\\Python-Prep\\M08_clasesyOOP\\herramientas.py') # Agrega la ruta al archivo 'herramientas.py' al sys.path\n",
    "import herramientas as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHerramientas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhola\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ines Sadir\\Desktop\\Python-Prep\\M09_errorhandling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(lista_numeros) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "f = h.Herramientas(\"hola\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Ines Sadir\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib  \n",
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,2,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros esperados son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados(1,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probando(unittest.TestCase):\n",
    "    \n",
    "    def test_crear_objeto1(self):\n",
    "        # se verifica que se genere una excepción de tipo ValueError\n",
    "        self.assertRaises(ValueError, h.Herramientas, 'esto es un parametro invalido')\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        h1 = h.Herramientas([1,2,2,5]) # verificar que la lista almacenada en el objeto h1\n",
    "        self.assertEqual(h1.lista, [1,2,2,5]) # sea igual a la lista param proporcionada como parámetro al crear el objeto.\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        h1 = h.Herramientas([1,2,1,3])\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        self.assertEqual(moda, [1, 2]) #verifica el funcionamiento de la funcion valor_modal que para [1,2,1,3] debe devolver [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.Probando.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.Probando.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.Probando.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.015s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2aaf3b39910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHerramientas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ines Sadir\\Desktop\\Python-Prep\\M09_errorhandling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(lista_numeros) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "i = h.Herramientas(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "        def test_verifica_primos1(self):\n",
    "                h1 = h.Herramientas([2,3,4,5])\n",
    "                primos = h1.verifica_primo()\n",
    "                self.assertEqual(primos, [True, True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.Probando.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.Probando.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.Probando.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.017s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2aaf31c0050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "        def test_verifica_primos1(self):\n",
    "                h1 = h.Herramientas([2, 3])\n",
    "                conv = h1.conversion_grados(\"kelvin\", \"celsius\")\n",
    "                self.assertEqual(conv, [-271.15, -270.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.Probando.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.Probando.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.Probando.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase3.test_verifica_primos1) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2aaf31ffe90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "        def test_verifica_factorial(self):\n",
    "                h1 = h.Herramientas([2, 3])\n",
    "                fact = h1.factorial()\n",
    "                self.assertEqual(fact, [4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.Probando.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.Probando.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.Probando.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_factorial (__main__.ProbandoMiClase3.test_verifica_factorial) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_verifica_factorial (__main__.ProbandoMiClase3.test_verifica_factorial)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ines Sadir\\AppData\\Local\\Temp\\ipykernel_1620\\4098379882.py\", line 5, in test_verifica_factorial\n",
      "    self.assertEqual(fact, [4, 6])\n",
      "AssertionError: Lists differ: [2, 6] != [4, 6]\n",
      "\n",
      "First differing element 0:\n",
      "2\n",
      "4\n",
      "\n",
      "- [2, 6]\n",
      "?  ^\n",
      "\n",
      "+ [4, 6]\n",
      "?  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.020s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2aaf3bccf10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
